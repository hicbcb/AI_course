{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN+dP+glTuCYUdXviIwWCza",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hicbcb/AI_course/blob/main/week10(%E6%95%99%E5%AD%B8%E7%94%A8)_GAN%E5%9C%96%E5%83%8F%E5%89%B5%E4%BD%9CMNIST(%E5%84%AA%E5%8C%96%E9%81%8E).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCaVsdEHhwg5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import imageio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 超參數設置\n",
        "latent_dim = 100\n",
        "img_shape = (1, 28, 28)  # MNIST 圖像大小\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 100\n",
        "sample_interval = 400  # 每隔多少個批次生成一次圖像\n",
        "max_norm = 1.0  # 增加梯度裁剪的閾值"
      ],
      "metadata": {
        "id": "SG4BEVYFw1na"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加載 MNIST 數據集\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),  # 調整圖像大小為 32x32\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZvO8ZemxJ_h",
        "outputId": "7e1fd4a7-757b-4a56-8472-980b30332031"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17188768.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 527406.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3806597.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2823555.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義生成器\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.ConvTranspose2d(latent_dim, 256, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = z.view(z.size(0), self.latent_dim, 1, 1)\n",
        "        img = self.model(z)\n",
        "        return img"
      ],
      "metadata": {
        "id": "WedCaDT-w5-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義判別器\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(128, 256, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        validity = self.model(img)\n",
        "        return validity"
      ],
      "metadata": {
        "id": "tgIFHMiRw6rA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientEarlyStopping:\n",
        "    def __init__(self, patience=5, threshold=1.0):\n",
        "        self.patience = patience\n",
        "        self.threshold = threshold\n",
        "        self.counter = 0\n",
        "        self.should_stop = False\n",
        "\n",
        "    def __call__(self, grad_norm):\n",
        "        if grad_norm > self.threshold:\n",
        "            self.counter += 1\n",
        "            if self.counter >= self.patience:\n",
        "                self.should_stop = True\n",
        "        else:\n",
        "            self.counter = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.counter = 0\n",
        "        self.should_stop = False"
      ],
      "metadata": {
        "id": "_WOBLIUxpw2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建生成器和判別器\n",
        "generator = Generator(latent_dim)\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "xGsjdMOWw_9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 調整生成器和判別器的學習率\n",
        "lr_g = 0.0002  # 生成器的學習率\n",
        "lr_d = 0.0002  # 判別器的學習率"
      ],
      "metadata": {
        "id": "NoEMK0SOpWU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義優化器\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "DBGKFI48xWSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 定義損失函數\n",
        "#criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "V1UppnTsxfwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 用於保存生成圖像的列表\n",
        "img_list = []"
      ],
      "metadata": {
        "id": "m-V2o8dtrxJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建 GradientEarlyStopping 實例\n",
        "# early_stopping = GradientEarlyStopping(patience=10, threshold=2.0)\n",
        "\n",
        "# 訓練循環\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (imgs, _) in enumerate(train_loader):\n",
        "\n",
        "        # 訓練判別器\n",
        "        z = torch.randn(imgs.size(0), latent_dim)\n",
        "        fake_imgs = generator(z)\n",
        "\n",
        "        real_validity = discriminator(imgs)\n",
        "        fake_validity = discriminator(fake_imgs.detach())\n",
        "\n",
        "        # 計算判別器損失\n",
        "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
        "\n",
        "        # 計算梯度懲罰項\n",
        "        alpha = torch.rand(imgs.size(0), 1, 1, 1)\n",
        "        interpolates = (alpha * imgs + (1 - alpha) * fake_imgs).requires_grad_(True)\n",
        "        d_interpolates = discriminator(interpolates)\n",
        "        fake = torch.ones_like(d_interpolates, requires_grad=False)\n",
        "        gradients = torch.autograd.grad(\n",
        "            outputs=d_interpolates,\n",
        "            inputs=interpolates,\n",
        "            grad_outputs=fake,\n",
        "            create_graph=True,\n",
        "            retain_graph=True,\n",
        "            only_inputs=True,\n",
        "        )[0]\n",
        "        gradients = gradients.view(gradients.size(0), -1)\n",
        "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "        d_loss += 10 * gradient_penalty  # 添加梯度懲罰項到判別器損失中\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "        d_loss.backward()\n",
        "\n",
        "        # 對判別器的梯度進行裁剪\n",
        "        torch.nn.utils.clip_grad_norm_(discriminator.parameters(), max_norm=max_norm)\n",
        "\n",
        "        optimizer_D.step()\n",
        "\n",
        "        # 訓練生成器\n",
        "        z = torch.randn(imgs.size(0), latent_dim)\n",
        "        fake_imgs = generator(z)\n",
        "        fake_validity = discriminator(fake_imgs)\n",
        "\n",
        "        # 計算生成器損失\n",
        "        g_loss = -torch.mean(fake_validity)\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "        g_loss.backward()\n",
        "\n",
        "        # 對生成器的梯度進行裁剪\n",
        "        torch.nn.utils.clip_grad_norm_(generator.parameters(), max_norm=max_norm)\n",
        "\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # 顯示圖\n",
        "        batches_done = epoch * len(train_loader) + i\n",
        "        if batches_done % sample_interval == 0:\n",
        "            # 生成一批圖像並添加到列表中\n",
        "            z = torch.randn(25, latent_dim)\n",
        "            labels = torch.randint(0, 10, (25,))  # 隨機生成25個數字標籤\n",
        "            gen_imgs = generator(z)\n",
        "            #print(\"Generator output shape:\", gen_imgs.shape)\n",
        "            #gen_imgs = gen_imgs.view(25, 1, 28, 28)\n",
        "\n",
        "\n",
        "            # 將數字標籤添加到生成的圖像上\n",
        "            fig, axs = plt.subplots(5, 5, figsize=(5, 5))\n",
        "            for j in range(5):\n",
        "                for k in range(5):\n",
        "                    idx = j * 5 + k\n",
        "                    axs[j, k].imshow(gen_imgs[idx].detach().cpu().numpy().squeeze(), cmap='gray')\n",
        "                    axs[j, k].set_title(str(labels[idx].item()), fontsize=12)\n",
        "                    axs[j, k].axis('off')\n",
        "            plt.tight_layout()\n",
        "            #plt.show()\n",
        "\n",
        "\n",
        "            # 將圖像轉換為 numpy 數組並添加到列表中\n",
        "            fig.canvas.draw()\n",
        "            img = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "            img = img.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "            # 將生成的圖像添加到列表中\n",
        "            img_list.append(img)\n",
        "\n",
        "            plt.close(fig)\n",
        "\n",
        "        # 計算生成器和判別器的梯度範數\n",
        "        grad_norm_g = torch.norm(torch.cat([p.grad.view(-1) for p in generator.parameters()]))\n",
        "        grad_norm_d = torch.norm(torch.cat([p.grad.view(-1) for p in discriminator.parameters()]))\n",
        "        '''\n",
        "        # 檢查梯度範數是否超過閾值\n",
        "        early_stopping(max(grad_norm_g, grad_norm_d))\n",
        "\n",
        "        if early_stopping.should_stop:\n",
        "            print(\"Training stopped due to gradient explosion.\")\n",
        "            break\n",
        "\n",
        "    if early_stopping.should_stop:\n",
        "        break\n",
        "        '''\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] D_loss: {d_loss.item():.4f} G_loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # 定期保存模型權重\n",
        "    if (epoch + 1) % 50 == 0:\n",
        "        torch.save(generator.state_dict(), f'generator_epoch_{epoch+1}.pth')\n",
        "        torch.save(discriminator.state_dict(), f'discriminator_epoch_{epoch+1}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "XfyWuUbjxkHd",
        "outputId": "6fb2b8ff-5f86-41e9-894b-bef413108666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] D_loss: -0.0214 G_loss: -0.0081\n",
            "Epoch [2/100] D_loss: -0.9824 G_loss: -0.0017\n",
            "Epoch [3/100] D_loss: 0.0440 G_loss: -0.4304\n",
            "Epoch [4/100] D_loss: -0.5793 G_loss: -0.0805\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-0f6807120024>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# 對判別器的梯度進行裁剪\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             )\n\u001b[0;32m--> 522\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    523\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 imageio 創建動圖\n",
        "with imageio.get_writer('gan_animation.gif', mode='I') as writer:\n",
        "    for img in img_list:\n",
        "        writer.append_data(img)"
      ],
      "metadata": {
        "id": "n8jWbwF9I97i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}